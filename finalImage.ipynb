{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c96e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from efficientnet) (0.19.3)\n",
      "Requirement already satisfied: h5py in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.8.4)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (22.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/realaryansharma/anaconda3/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.10.0)\n",
      "Installing collected packages: keras-applications, efficientnet\n",
      "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7beceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e2f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 517 images belonging to 3 classes.\n",
      "Found 129 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Flatten, BatchNormalization, Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from efficientnet.keras import EfficientNetB0\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to load and split your dataset\n",
    "def load_and_split_data(data_dir, test_size=0.2, random_state=42):\n",
    "    data_gen = ImageDataGenerator(rescale=1./255, validation_split=test_size)\n",
    "    train_set = data_gen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(224, 224),  # Revert back to 224x224\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_set = data_gen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(224, 224),  # Revert back to 224x224\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "training_set, test_set = load_and_split_data(data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4766b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,\n",
    "    classes=3  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ba1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output layer for binary classification\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb92bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnet-b0 (Functiona  (None, 7, 7, 1280)        4049564   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 1280)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 62720)             0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 62720)             250880    \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2007072   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6307743 (24.06 MB)\n",
      "Trainable params: 2132675 (8.14 MB)\n",
      "Non-trainable params: 4175068 (15.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6092ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    BinaryAccuracy(name='accuracy'),\n",
    "    Precision(name='precision'),\n",
    "    Recall(name='recall'),\n",
    "                                \n",
    "    AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# Define callbacks\n",
    "lrd = ReduceLROnPlateau(monitor='val_loss', patience=20, verbose=1, factor=0.50, min_lr=1e-10)\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "es = EarlyStopping(verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9842b26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e048be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.7660 - precision: 0.6799 - recall: 0.5629 - auc: 0.8042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/realaryansharma/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 8s 373ms/step - loss: 0.8670 - accuracy: 0.7660 - precision: 0.6799 - recall: 0.5629 - auc: 0.8042 - val_loss: 2.1568 - val_accuracy: 0.7623 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.7947 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.3514 - accuracy: 0.9407 - precision: 0.9493 - recall: 0.8685 - auc: 0.9807 - val_loss: 1.0770 - val_accuracy: 0.7881 - val_precision: 0.6880 - val_recall: 0.6667 - val_auc: 0.8556 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 0.2531 - accuracy: 0.9691 - precision: 0.9776 - recall: 0.9284 - auc: 0.9952 - val_loss: 0.8168 - val_accuracy: 0.8140 - val_precision: 0.7355 - val_recall: 0.6899 - val_auc: 0.8778 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.1725 - accuracy: 0.9884 - precision: 0.9902 - recall: 0.9749 - auc: 0.9993 - val_loss: 0.7385 - val_accuracy: 0.8217 - val_precision: 0.7459 - val_recall: 0.7054 - val_auc: 0.8853 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.1349 - accuracy: 0.9936 - precision: 0.9961 - recall: 0.9845 - auc: 0.9997 - val_loss: 0.7233 - val_accuracy: 0.8191 - val_precision: 0.7438 - val_recall: 0.6977 - val_auc: 0.8816 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.1179 - accuracy: 0.9948 - precision: 0.9961 - recall: 0.9884 - auc: 0.9999 - val_loss: 0.6847 - val_accuracy: 0.8269 - val_precision: 0.7583 - val_recall: 0.7054 - val_auc: 0.8907 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.0921 - accuracy: 0.9968 - precision: 0.9961 - recall: 0.9942 - auc: 0.9998 - val_loss: 0.6493 - val_accuracy: 0.8269 - val_precision: 0.7583 - val_recall: 0.7054 - val_auc: 0.9002 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.0743 - accuracy: 0.9981 - precision: 0.9981 - recall: 0.9961 - auc: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8269 - val_precision: 0.7541 - val_recall: 0.7132 - val_auc: 0.9018 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 0.0638 - accuracy: 0.9974 - precision: 0.9981 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.6457 - val_accuracy: 0.8295 - val_precision: 0.7603 - val_recall: 0.7132 - val_auc: 0.8981 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.0617 - accuracy: 0.9961 - precision: 0.9961 - recall: 0.9923 - auc: 0.9999 - val_loss: 0.6551 - val_accuracy: 0.8346 - val_precision: 0.7600 - val_recall: 0.7364 - val_auc: 0.8937 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[lrd, mcp, es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e638348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and resize the test image to match the model's input shape\n",
    "test_image = image.load_img('../updatedImageSet2/angry/3880250382_260e6466c0_b.jpg', target_size=(224, 224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Normalize the image\n",
    "test_image /= 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa57084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 516ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make a prediction using the model\n",
    "result = model.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a60a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices = training_set.class_indices\n",
    "class_labels = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class_index = np.argmax(result)\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "predicted_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f7d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../saved_models/finalImageModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd613f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
